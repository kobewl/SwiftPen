# SwiftPen V2 新功能说明

## 🎉 新增功能

### 1. 多 AI 服务支持

SwiftPen 现在支持多种 AI 服务提供商，让你可以根据需求选择最适合的服务！

#### 支持的服务

| 服务 | 模型 | 特点 |
|------|------|------|
| **OpenAI** | GPT-3.5, GPT-4, GPT-4 Turbo, GPT-4o, GPT-4o Mini | 强大、稳定、功能全面 |
| **Google Gemini** | Gemini Pro, Gemini 1.5 Pro, Gemini 1.5 Flash | Google 的最新 AI，免费额度大 |
| **自定义** | 任何兼容 OpenAI 格式的 API | 支持 Claude、Ollama、本地模型等 |

#### 使用方法

1. 进入 **设置 → SwiftPen**
2. 在 "写作服务提供商" 中选择你要使用的服务
3. 填写对应服务的 **API Key** 和配置
4. 开始使用！

#### OpenAI 配置

```
API Key: sk-...
Base URL: https://api.openai.com/v1
模型: gpt-3.5-turbo / gpt-4 / gpt-4o / gpt-4o-mini
```

适用于：
- 需要最强大 AI 能力
- 对质量要求高
- 不介意付费使用

#### Gemini 配置

```
API Key: AIza...
Base URL: https://generativelanguage.googleapis.com/v1beta
模型: gemini-pro / gemini-1.5-pro / gemini-1.5-flash
```

适用于：
- 想使用免费服务
- Google 生态用户
- 需要多语言支持

获取 API Key：
1. 访问 [Google AI Studio](https://aistudio.google.com/)
2. 创建 API Key
3. 复制到设置中

#### 自定义 API 配置

```
API Key: 你的密钥
Base URL: http://localhost:11434/v1  (例如 Ollama)
模型: llama2 / claude-3-opus / etc.
```

适用于：
- 使用 Ollama 等本地模型
- 使用 Claude 等其他服务
- 自建 AI 服务
- 完全离线使用

### 2. 选词翻译功能 ✨

全新的一键翻译功能，让你轻松翻译文本！

#### 使用方法

1. **选中**要翻译的文本
2. 按 `Ctrl+Shift+T` (Mac: `Cmd+Shift+T`)
3. AI 自动翻译并替换选中内容

#### 特点

- 🚀 **快速翻译** - 一键即可
- 🌍 **多语言支持** - 支持 9 种常见语言
- 🔄 **智能检测** - 自动检测源语言
- 🎯 **上下文理解** - AI 理解语境，翻译更准确
- 📝 **保留格式** - 保持原文的 Markdown 格式

#### 支持的语言

- 简体中文 (zh-CN)
- 繁体中文 (zh-TW)
- 英语 (en)
- 日语 (ja)
- 韩语 (ko)
- 法语 (fr)
- 德语 (de)
- 西班牙语 (es)
- 俄语 (ru)

#### 配置选项

在设置中可以配置：
- **翻译服务提供商** - 选择用于翻译的 AI 服务
- **目标语言** - 默认翻译到什么语言
- **源语言** - 自动检测或指定源语言

#### 使用场景

**场景 1：英译中**
```markdown
选中: "Hello World"
按 Ctrl+Shift+T
结果: "你好世界"
```

**场景 2：中译英**
```markdown
选中: "人工智能正在改变世界"
按 Ctrl+Shift+T  
结果: "Artificial intelligence is changing the world"
```

**场景 3：保留 Markdown 格式**
```markdown
选中: "**Important**: Read this carefully"
按 Ctrl+Shift+T
结果: "**重要**：仔细阅读"
```

### 3. 性能优化 ⚡

#### 智能缓存系统

为了提高响应速度和减少 API 调用，我们添加了智能缓存：

- ✅ **自动缓存** - 相同的请求会直接返回缓存结果
- ⏱️ **可配置超时** - 默认 30 分钟，可自定义
- 💰 **节省成本** - 减少重复的 API 调用
- 🚀 **即时响应** - 缓存命中时无需等待

#### 配置方法

在设置中：
1. 启用/禁用缓存
2. 设置缓存超时时间（分钟）

#### 缓存策略

- 相同的上下文 + 相同的需求 = 使用缓存
- 超过设定时间后自动失效
- 切换 AI 服务时自动清空

#### 性能对比

| 场景 | 无缓存 | 有缓存 |
|------|--------|--------|
| 首次请求 | 2-5秒 | 2-5秒 |
| 重复请求 | 2-5秒 | <0.1秒 |
| API 调用 | 100% | ~30% |
| 成本 | 全额 | 节省 70% |

### 4. 改进的设置界面 🎨

#### 新的设置结构

设置页面现在按功能分组，更加清晰：

```
📝 AI 服务提供商
   └─ 选择写作服务 (OpenAI/Gemini/自定义)

🔧 [对应服务的配置]
   ├─ API Key
   ├─ Base URL
   └─ 模型选择

⚙️ 通用配置
   ├─ 最大生成长度
   ├─ 创造性（Temperature）
   ├─ 上下文长度
   └─ 系统提示词

🌍 翻译配置
   ├─ 翻译服务提供商
   ├─ 目标语言
   └─ 源语言

⚡ 性能优化
   ├─ 启用缓存
   └─ 缓存超时
```

#### 动态界面

- 切换 AI 服务时，界面自动显示对应的配置选项
- 只显示当前需要的设置项
- 清晰的说明和提示

## 📊 功能对比

### V1 vs V2

| 功能 | V1 | V2 |
|------|----|----|
| AI 服务 | 仅 OpenAI | OpenAI + Gemini + 自定义 |
| 翻译功能 | ❌ | ✅ |
| 缓存系统 | ❌ | ✅ |
| 本地模型 | ❌ | ✅ (通过自定义) |
| 设置界面 | 基础 | 分组优化 |

## 🚀 快速开始

### 使用 OpenAI（付费）

1. 进入设置 → 选择 "OpenAI"
2. 输入 API Key
3. 选择模型（推荐 gpt-3.5-turbo）
4. 开始使用

### 使用 Gemini（免费）

1. 访问 [Google AI Studio](https://aistudio.google.com/)
2. 创建免费 API Key
3. 进入设置 → 选择 "Gemini"
4. 输入 API Key
5. 开始使用

### 使用 Ollama（本地免费）

1. 安装 [Ollama](https://ollama.ai/)
2. 运行本地模型：`ollama run llama2`
3. 进入设置 → 选择 "自定义"
4. 配置：
   - API Key: `ollama` (随意填写)
   - Base URL: `http://localhost:11434/v1`
   - 模型: `llama2`
5. 开始使用

## 💡 使用技巧

### 技巧 1：混合使用多个服务

你可以为不同的任务使用不同的服务：

- **写作服务**：使用 GPT-4（质量高）
- **翻译服务**：使用 Gemini（免费且好用）

这样可以在质量和成本之间取得平衡！

### 技巧 2：利用缓存节省成本

对于重复性的写作任务：
1. 启用缓存
2. 设置较长的缓存时间（如 60 分钟）
3. 相同的请求直接使用缓存
4. 大幅降低 API 成本

### 技巧 3：本地模型用于草稿

对于初稿和实验：
- 使用 Ollama 本地模型（完全免费）
- 快速迭代和试验
- 最终版本使用 GPT-4 润色

### 技巧 4：翻译工作流

1. 用中文快速写作
2. 选中需要翻译的部分
3. `Ctrl+Shift+T` 一键翻译
4. 继续编辑

或反过来：
1. 从英文资料复制内容
2. 粘贴到笔记
3. 选中并翻译成中文
4. 理解和学习

## ❓ 常见问题

### Q: 如何选择 AI 服务？

**A**: 根据你的需求：
- **追求质量** → OpenAI GPT-4
- **免费使用** → Google Gemini
- **隐私优先** → Ollama 本地模型
- **成本优化** → Gemini (翻译) + GPT-3.5 (写作)

### Q: Gemini 免费吗？

**A**: 是的！Google AI Studio 提供免费的 API 配额：
- 每分钟 60 次请求
- 足够个人使用

### Q: 如何使用本地模型？

**A**: 通过 Ollama：
```bash
# 安装 Ollama
# 访问 https://ollama.ai/

# 下载模型
ollama pull llama2
ollama pull mistral

# 运行模型
ollama run llama2
```

然后在 SwiftPen 中选择"自定义"并配置 Ollama 地址。

### Q: 缓存会影响结果吗？

**A**: 
- 相同的输入 → 返回缓存（确保一致性）
- 不同的输入 → 正常调用 AI
- 可以随时禁用缓存

### Q: 翻译质量如何？

**A**: 
- 使用 AI 翻译，理解上下文
- 质量通常优于传统翻译工具
- 推荐使用 GPT-4 获得最佳效果

### Q: 可以同时使用多个服务吗？

**A**: 可以！
- 写作使用一个服务
- 翻译使用另一个服务
- 在设置中分别配置

## 🎯 下一步

- [ ] 添加更多 AI 服务（Claude 官方支持等）
- [ ] 批量翻译功能
- [ ] 翻译历史记录
- [ ] 自定义翻译提示词
- [ ] 更多性能优化

## 💬 反馈

有问题或建议？欢迎在 GitHub Issues 中告诉我们！

---

**享受 SwiftPen V2 带来的全新体验！** ✨

